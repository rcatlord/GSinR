---
title: "Analysing Data in R"
author: "RÃ©ka Solymosi, Henry Partridge & Sam Langton"
date: "5 July 2018"
output:
  html_document: default
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, prompt=FALSE, tidy=TRUE, comment=NA, message=TRUE, warning=FALSE)

# load necessary packages
```

***

So now that you are familiar with the R syntax, know how to import data, and know how to get that data into the shape and form that you need for your analysis, we can begin to perform some basic operations to explore your data. 

In your normal workflow, we are conscious that lot of your data exploration will come from visualisation. We cover visualisation tomorrow though, so we will stick to your basic stats in this session. We will cover

- Univariate analysis (summary stats)
- Bivariate analysis (chi-square test, t-test, anova)

We just want to note that this tutorial is not meant to be a primer in stats, rather just an illustration of how to do these stats in R. We assume that you are already familiar with these techniques. If not, there are a variety of statistics resources out there which you can go through after the course. You might find [this](https://www.amazon.co.uk/Discovering-Statistics-Using-Andy-Field/dp/1446200469) a useful book, but as with all R related stuff, there are plenty of free online resources.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
```

#The data

We will be working through the gapminder data set again. To load this data set into your environment, load the package: 

```{r}
library(gapminder)
```

But we also want to do some data manipulation by filtering and creating a new variable we will use later. 

```{r}

gapminder_2007 <- gapminder %>%
  filter(year==2007) %>%
  mutate(gdp_factor = if_else(gdpPercap > mean(gdpPercap), "high gdp", "low gdp"), 
         below_avg_life_exp = if_else(lifeExp < mean(lifeExp), "low life expectancy", "high life expectancy"))

gapminder_2007$gdp_factor <- as.factor(gapminder_2007$gdp_factor)
gapminder_2007$below_avg_life_exp <- as.factor(gapminder_2007$below_avg_life_exp)

```


#Univariate stats

```{r}
summary(gapminder_2007$gdpPercap)
```

```{r}
sd(gapminder_2007$gdpPercap)
```

```{r}
summary(gapminder_2007$gdp_factor)
```

For the whole dataframe

```{r}
summary(gapminder_2007)
```


#Bivariate stats

##Numeric - numeric

###Correlation


R can perform correlation with the `cor()` function. Built-in to the base distribution of the program are three routines; for Pearson, Kendal and Spearman Rank correlations.


The pseudo code to get the correlation coefficient would be:


```{r, eval=FALSE}
cor(var1, var2, method = "method")
```


Correlation coefficients
- The default correlation returns the pearson correlation coefficient:	`cor(var1, var2)`
- If you specify "spearman" you will get the spearman correlation coefficient:	`cor(var1, var2, method = "spearman")` and you can also do this for kendall.
- If you use a datset instead of separate variables you will return a matrix of all the pairwise correlation coefficients:	`cor(dataset, method = "pearson")`


Getting a correlation coefficient is generally only half the story; you will want to know if the relationship is statistically significant. The `cor()` function in R can be extended to provide the significance testing required. The function is `cor.test()`


To run a correlation test, the pseudo code would look like this:


```{r, eval=FALSE}
cor.test(var1, var2, method = "method")
```


As with `cor` you can specify which correlation method you need e.g. spearman, kendall, pearson.

As usual with R it is a good idea to assign a variable name to your result in case you want to perfom additional operations. To see a summary of your correlation test type the name of the variable e.g. `cor.s`

So if we want to test the correlation between life expectancy and GDP per capita, using a pearson correlation, then we would do the following: 


```{r}

gapminder_corr <- cor.test(gapminder_2007$lifeExp, gapminder_2007$gdpPercap)
gapminder_corr

```


You can also plot the correlation coefficient on top of a scatterplot of the variables:


```{r}
ggplot(gapminder_2007, aes(x = lifeExp, y = gdpPercap)) +
  geom_point() +
  geom_smooth(colour = "red", fill = "lightgreen", method = 'lm')
```


Finally, you can get a correlation matrix, to assess the relationship between all your variables in your data set. For this, we need to select only the quantitative variables in our data set. We should be experts at such subsetting by now, so let's do this by **select**ing the quantitative variables: 


```{r}

quant_gap <- gapminder_2007 %>%
  select(lifeExp, pop, gdpPercap)

```


Now print a correlation table of all the quantitative variables:


```{r}

res <- cor(quant_gap)
round(res, 2)

```



You can also use the `corrplot` package to visualise this:



```{r, eval=FALSE}

install.packages("corrplot")
```


```{r}

library(corrplot)
corrplot(cor(quant_gap), type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```


The function `corrplot()` takes the correlation matrix as the first argument. The second argument `(type="upper")` is used to display only the upper triangular of the correlation matrix.



##Categorical - categorical

###Chi-square

So you want to look at a cross-tab between two variables. This is as easy as using the `table()` function, and passing it the two variables as arguments. For example, if we want to look at the relationship between our two dichotomous variables we created about high and low gdp and also below average life expectancy or not, we can just type: 


```{r}
table(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp)
```


Excellent, now we can run a chi square test with the... `chisq.test()` function. Inside the brackets you have to pass a frequency table. Like the one we made below. This can be something you saved as an object, or you can just recreate the table inside the function. 


Very straightforward. Now what we want to do is save this to an object: 


```{r}

life_exp_v_gdp <- chisq.test(table(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp))
```


Now, we can call all sorts of information from this chi square test object: 


Your test statistic:


```{r}
life_exp_v_gdp$statistic
```


Your degress of freedom:


```{r}
  life_exp_v_gdp$parameter
```


Your p value: 


```{r}
  life_exp_v_gdp$p.value
```


Your expected counts for the cells: 


```{r}
  life_exp_v_gdp$expected
```


Your residuals:


```{r}
  life_exp_v_gdp$residuals
```


Your standardized residuals: 


```{r}
  life_exp_v_gdp$stdres
```


However if you want to see it all together, you can use the `CrossTable()` function from the `gmodels` package: 


```{r, eval=FALSE}
  install.packages("gmodels")
```


You can even specify for your table to follow the format you might be familiar with from SPSS or SAS. Use `?CrossTable()` to see all the parameters you can specify with this function:  


```{r}
library(gmodels)
CrossTable(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp , prop.t=FALSE, prop.r=FALSE, prop.c=FALSE, expected = TRUE, resid = TRUE, sresid = TRUE, format = "SPSS")

```

###Fisher test


Now since we are all stats-minded people, you may have noticed that we have a very low cell count in one of our cells in our contingency table. Since this can call into doubt our findings, it's always helpful to use tests that account for these issues as well. In this case, the test would be a Fisher exact test, which you carry out in R with the `fisher-test()` function. This function also just needs a contingency table passed to it as an argument: 


```{r}
fisher.test(table(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp))
```


###Odds ratio

To get the odds ratio from a 2 x 2 cross tab, you can use the `oddsratio()` function from the `vcd` package. 


```{r, eval=FALSE}
install.packages("vcd")
```


And again, all you need to pass it, is a contingency table, and an argument to specify that you want odds ratio, and not log odds

```{r}
library(vcd)
oddsratio(table(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp), log = FALSE) 
```


You can see how it's blank where it says "and". If you pass it a table with column names, it would tell you what your odds ratio is being calculated for. But luckily with the code right there, we still see, and if we were to forge the values, we can always just re-print the table. In this case, we know now that the odds of having below-average life expectancy for low gdp countries are 19 times the odds for high gdp countries. 


But we know that we had issues with the small cell count, and in general in stats we like to be explicit about our uncertainties, so let's also include some confidence intervals here. So a final step is to do this with the `confint()` function: 


```{r}
confint(oddsratio(table(gapminder_2007$gdp_factor, gapminder_2007$below_avg_life_exp), log = FALSE) )
```



##Categorical - numeric

Finally we want to look at the differences in a numeric value between groups.  As mentioned, we don't go into the stats, just how to run the stats in R, but we just wanted to mention that what we cover here, the t-test and the anova test, both have the assumption that the numeric variable is normally distributed. If not, we would want to use non-parametric alternatives. [Here is a quick guide](http://www.statmethods.net/stats/nonparametric.html) on these, that will give you pointers on how to run these test. But here we will focus just on the t-test and the anova test. 


###T-test

For categorical variables with two possible values, we would use the t-test, if the numeric variable meets the assumption of normal distribution. By now you should be able to guess what functions are called in R! Any ideas for the t-test? 

Well... the function is called `t.test()`. The R function `t.test()` can be used to perform both one and two sample t-tests on vectors of data.
The function contains a variety of options and can be called as follows:


```{r, eval=FALSE}
t.test(x ~ y, alternative = c("two.sided", "less", "greater"), mu = 0, paired =
FALSE, var.equal = FALSE, conf.level = 0.95)
```


Here, x is a numeric vector of data values and y is a binary factor. The option `mu` provides a number indicating the true value of the mean (or difference in means if you are performing a two sample test) under the null hypothesis. The option alternative is a character string specifying the alternative hypothesis, and must be one of the following: "two.sided" (which is the default), "greater" or "less" depending on whether the alternative hypothesis is that the mean is different than, greater than or less than mu, respectively. 


For example the following call:


```{r, eval=FALSE}
t.test(x, alternative = "less", mu = 10)
```


performs a one sample t-test on the data contained in x where the null hypothesis is that =10 and the alternative is that <10. The option paired indicates whether or not you want a paired t-test (TRUE = yes and FALSE = no). If you leave this option out it defaults to FALSE. The option var.equal is a logical variable indicating whether or not to assume the two variances as being equal when performing a two-sample t-test. If TRUE then the pooled variance is used to estimate the variance otherwise the Welch (or Satterthwaite) approximation to the degrees of freedom is used. If you leave this option out it defaults
to FALSE. Finally, the option conf.level determines the confidence level of the reported confidence interval for in the one-sample case and 1- 2 in the two-sample case.


So if we want to look at life expectancy between high and low gdp countries, using a t-test, we would: 


```{r}

t.test(gapminder_2007$lifeExp ~ gapminder_2007$gdp_factor, alternative = "two.sided", paired=FALSE, conf.level = 0.95)
```


So now you can say that the difference in mean life expectancy between high and low gdp countries is statistically significant, and is between 11 - 17 years. 


###ANOVA

And what about the difference in life expectancy between continents? The function here is called `aov()` and the setup is very similar to the t.test(): 


```{r, eval=FALSE}
fit <- aov(x ~ y, data=mydataframe)
```


Where x refers to the numeric variable, and y to the categorical variable with multiple possible values. You also specify the data souce, so you only have to use the column names as the x and the y values. [For other variations of ANOVA, eg two factor design, see this quick start guide](http://www.statmethods.net/stats/anova.html)


```{r}

fit <- aov(lifeExp ~ continent, data = gapminder_2007)
summary(fit)
```

You also want to carry out post-hoc testing: 


```{r}
TukeyHSD(fit)
```




#Resources
- [Mark Gardener, Using R for statistical analyses](http://www.stat.columbia.edu/~martin/W2024/R2.pdf)
- [Introduction to Statistical Learning with applications in R](http://www-bcf.usc.edu/~gareth/ISL/)
- [Juanjo Medina, R-for-Criminologists](https://jjmedinaariza.github.io/R-for-Criminologists/)
